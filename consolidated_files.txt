===== File: server.js =====
/**
 * server.js
 * Entry point that initializes Express, connects to MongoDB,
 * and sets up the routes & queue worker.
 */

require('dotenv').config();

const express = require('express');
const mongoose = require('mongoose');
const { initQueueWorker } = require('./services/docProcessingQueue');
const documentRoutes = require('./routes/documentRoutes');

async function initLearningLabModule() {
  // 1. Connect to MongoDB
  await mongoose.connect(process.env.MONGODB_URI);

  // 2. Initialize Express
  const app = express();
  app.use(express.json());

  // 3. Add a home route for the root path
  app.get('/', (req, res) => {
    res.send('Welcome to the Learning Lab Module API');
  });

  // 4. Attach Routes
  app.use('/documents', documentRoutes);

  // 5. Initialize Queue Worker
  initQueueWorker();

  // 6. Start Server
  const PORT = process.env.PORT || 3000;
  app.listen(PORT, () => {
    console.log(`Learning Lab Module running on port ${PORT}`);
  });
}

// Optionally, start the module immediately:
initLearningLabModule();

module.exports = { initLearningLabModule };


===== File: models/documentModel.js =====
/**
 * models/documentModel.js
 * Mongoose schema and model for Document metadata.
 */

const mongoose = require('mongoose');

const DocumentSchema = new mongoose.Schema({
  name: String, // user-supplied document name
  filename: String,
  fileType: String,
  s3Key: String,
  uploadDate: { type: Date, default: Date.now },
  tags: [String],
  status: { type: String, default: 'uploaded' },
  extractedText: String,
  summary: String,
});

module.exports = mongoose.model('Document', DocumentSchema);


===== File: controllers/documentController.js =====
/**
 * controllers/documentController.js
 * Contains controller functions for Document-related operations:
 *  - Uploading a document with file, name, and tag(s)
 *  - Adding/updating tags
 *  - Getting processing status
 *  - Searching documents by name and tag(s)
 *  - Deleting a document
 */

const DocumentModel = require('../models/documentModel');
const { uploadFileToS3 } = require('../services/s3Service');
const { docProcessQueue } = require('../services/docProcessingQueue');
const { v4: uuidv4 } = require('uuid');

// Upload Document
async function uploadDocument(req, res) {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file provided.' });
    }
    const file = req.file;
    const fileId = uuidv4();
    const fileKey = `docs/${fileId}_${file.originalname}`;

    // Upload file to S3
    await uploadFileToS3(fileKey, file.buffer);

    // Construct the S3 URI using the bucket name from the environment variables
    const s3Uri = `s3://${process.env.S3_BUCKET}/${fileKey}`;

    // Use provided name or default to original file name
    const name = req.body.name || file.originalname;

    // Parse tags if provided (expects a comma‐separated string or an array)
    let tags = [];
    if (req.body.tags) {
      if (typeof req.body.tags === 'string') {
        tags = req.body.tags.split(',').map(tag => tag.trim());
      } else if (Array.isArray(req.body.tags)) {
        tags = req.body.tags;
      }
    }

    // Create DB record with provided name, file details, and tags
    const newDoc = await DocumentModel.create({
      name: name,
      filename: file.originalname,
      fileType: file.mimetype,
      s3Key: fileKey,
      tags: tags,
    });

    // Add job to queue (processing runs asynchronously)
    docProcessQueue.add({ docId: newDoc._id });

    const responseMessage = {
      message: 'File uploaded successfully',
      documentId: newDoc._id,
      s3Uri: s3Uri,
    };
    console.log("Upload response:", responseMessage);
    return res.json(responseMessage);
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Upload failed.' });
  }
}

// Add or Update Tags
async function addOrUpdateTags(req, res) {
  try {
    const { tags } = req.body;
    const docId = req.params.id;
    const doc = await DocumentModel.findById(docId);
    if (!doc) {
      return res.status(404).json({ error: 'Document not found.' });
    }
    doc.tags = Array.isArray(tags) ? tags : [];
    await doc.save();
    return res.json({ message: 'Tags updated.', document: doc });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Tag update failed.' });
  }
}

// Get Document Status
async function getDocumentStatus(req, res) {
  try {
    const doc = await DocumentModel.findById(req.params.id).lean();
    if (!doc) {
      return res.status(404).json({ error: 'Document not found.' });
    }
    return res.json({ document: doc });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Status check failed.' });
  }
}

// Search Documents by Name and Tags
async function searchDocuments(req, res) {
  try {
    const { name, tags } = req.query;
    let query = {};

    if (name) {
      // Search in the 'name' field (case-insensitive)
      query.name = { $regex: name, $options: 'i' };
    }
    if (tags) {
      const tagList = typeof tags === 'string'
        ? tags.split(',').map(t => t.trim())
        : tags;
      query.tags = { $all: tagList };
    }
    const docs = await DocumentModel.find(query).lean();
    return res.json({ documents: docs });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Search failed.' });
  }
}

// Delete Document
async function deleteDocument(req, res) {
  try {
    const docId = req.params.id;
    const doc = await DocumentModel.findByIdAndDelete(docId);
    if (!doc) {
      return res.status(404).json({ error: 'Document not found.' });
    }
    // Optionally, delete the file from S3 here
    return res.json({ message: 'Document deleted successfully.' });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Deletion failed.' });
  }
}

module.exports = {
  uploadDocument,
  addOrUpdateTags,
  getDocumentStatus,
  searchDocuments,
  deleteDocument,
};


===== File: routes/documentRoutes.js =====
/**
 * routes/documentRoutes.js
 * Express Router for all /documents endpoints:
 *   - /upload           (POST)          -> Upload document with file, name, and tag(s)
 *   - /:id/tags         (POST)          -> Add or update tags
 *   - /:id/status       (GET)           -> Get processing status
 *   - /                 (GET)           -> Search documents by name and tag(s)
 *   - /:id              (DELETE)        -> Delete document
 */

const express = require('express');
const multer = require('multer');
const {
  uploadDocument,
  addOrUpdateTags,
  getDocumentStatus,
  searchDocuments,
  deleteDocument,
} = require('../controllers/documentController');

const router = express.Router();

// Configure Multer (in-memory)
const storage = multer.memoryStorage();
const upload = multer({
  storage,
  limits: { fileSize: 1024 * 1024 * 1024 }, // 1GB
});

// Routes
router.post('/upload', upload.single('file'), uploadDocument);
router.post('/:id/tags', addOrUpdateTags);
router.get('/:id/status', getDocumentStatus);
router.get('/', searchDocuments);
router.delete('/:id', deleteDocument);

module.exports = router;


===== File: services/docProcessingQueue.js =====
/**
 * services/docProcessingQueue.js
 * Sets up a Bull queue for asynchronous document processing (OCR, summarization, LLM).
 */

const Bull = require('bull');
const DocumentModel = require('../models/documentModel');
const { downloadFileFromS3 } = require('./s3Service');

// Create the Queue
const docProcessQueue = new Bull('docProcessQueue', {
  redis: { host: '127.0.0.1', port: 6379 },
});

// Main Worker Initialization
function initQueueWorker() {
  docProcessQueue.process(async (job) => {
    try {
      console.log("Processing job:", job.id);
      const { docId } = job.data;
      const docRecord = await DocumentModel.findById(docId);
      if (!docRecord) throw new Error('Document not found in DB');
      console.log("Document record found:", docRecord);

      // 1. Download file from S3
      console.log("Downloading file from S3 with key:", docRecord.s3Key);
      const fileBuffer = await downloadFileFromS3(docRecord.s3Key);
      console.log("File downloaded, size:", fileBuffer.length);

      // 2. Extract text
      console.log("Extracting text...");
      const extractedText = await TextExtraction(fileBuffer, docRecord.fileType);
      console.log("Text extracted (first 100 chars):", extractedText.substring(0, 100));

      // 3. Summarize text
      console.log("Summarizing text...");
      const summary = await Summarization(extractedText);
      console.log("Summary generated:", summary);

      // 4. Integrate with LLM (placeholder)
      console.log("Integrating with LLM...");
      await LLMIntegration(extractedText, summary);

      // 5. Update MongoDB record
      docRecord.extractedText = extractedText;
      docRecord.summary = summary;
      docRecord.status = 'processed';
      await docRecord.save();
      console.log("Document record updated successfully for job:", job.id);
    } catch (error) {
      console.error("Error processing job", job.id, error);
      throw error;
    }
  });
}

// Updated Text Extraction Function to handle various file types
async function TextExtraction(fileBuffer, fileType) {
  if (fileType.startsWith('image/')) {
    // Use Tesseract.js for OCR on images
    const { createWorker } = require('tesseract.js');
    const worker = createWorker();
    await worker.load();
    await worker.loadLanguage('eng');
    await worker.initialize('eng');
    const { data: { text } } = await worker.recognize(fileBuffer);
    await worker.terminate();
    return text;
  } else if (fileType === 'application/pdf') {
    // Use pdf-parse for PDF documents
    const pdfParse = require('pdf-parse');
    const data = await pdfParse(fileBuffer);
    return data.text;
  } else if (fileType === 'text/csv') {
    // CSV files are plain text
    return fileBuffer.toString('utf8');
  } else if (
    fileType === 'application/vnd.ms-excel' ||
    fileType === 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
  ) {
    // Use xlsx to convert Excel files to CSV text
    const xlsx = require('xlsx');
    const workbook = xlsx.read(fileBuffer, { type: 'buffer' });
    let text = '';
    workbook.SheetNames.forEach(sheetName => {
      const sheet = workbook.Sheets[sheetName];
      text += xlsx.utils.sheet_to_csv(sheet);
    });
    return text;
  } else if (
    fileType === 'application/msword' ||
    fileType === 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
  ) {
    // Use mammoth to extract text from DOC/DOCX files
    const mammoth = require('mammoth');
    const result = await mammoth.extractRawText({ buffer: fileBuffer });
    return result.value;
  } else if (fileType.startsWith('video/')) {
    // Placeholder: Video transcription is not implemented
    return "Video transcription not implemented.";
  } else {
    // Fallback: treat as plain text
    return fileBuffer.toString('utf8');
  }
}

// Placeholder Summarization Function
async function Summarization(fullText) {
  // In production, replace this with a call to a summarization service or model
  return `Summary placeholder for text: ${fullText.slice(0, 50)}...`;
}

// Placeholder LLM Integration Function
async function LLMIntegration(extractedText, summary) {
  console.log('LLM updated with new document content and summary.');
}

module.exports = {
  docProcessQueue,
  initQueueWorker,
};


===== File: services/s3Service.js =====
/**
 * services/s3Service.js
 * AWS S3 integration for uploading and downloading files.
 */

const { S3Client, PutObjectCommand, GetObjectCommand } = require('@aws-sdk/client-s3');

const REGION = process.env.AWS_REGION || 'us-east-1';
const BUCKET_NAME = process.env.S3_BUCKET;

const s3Client = new S3Client({ region: REGION });

async function uploadFileToS3(key, buffer) {
  const command = new PutObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
    Body: buffer,
  });
  await s3Client.send(command);
}

async function downloadFileFromS3(key) {
  const command = new GetObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
  });
  const data = await s3Client.send(command);
  return data.Body;
}

module.exports = {
  uploadFileToS3,
  downloadFileFromS3,
};


