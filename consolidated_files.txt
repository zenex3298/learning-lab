===== List of Files =====
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/.DS_Store
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/server.js
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/README.md
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/.gitignore
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/package-lock.json
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/package.json
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/.env
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/models/documentModel.js
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/nudity.jpg
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/test_upload.sh
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/.DS_Store
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/video/.DS_Store
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/video/sample_video.mp4
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/images/.DS_Store
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/images/sample_jpg.jpg
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/images/sample_png.png
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/sample.exe
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/.DS_Store
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/sample.csv
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/sample.doc
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/sample.pdf
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/sample.xls
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/docs/sample.txt
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/audio/.DS_Store
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/sample_documents/audio/sample_audio.mp3
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/controllers/documentController.js
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/routes/documentRoutes.js
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/services/docProcessingQueue.js
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/services/s3Service.js
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/document.wflow
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/Info.plist
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/_CodeSignature/CodeResources
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/MacOS/Automator Application Stub
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/Resources/ApplicationStub.icns
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/Resources/Assets.car
/Users/Mike/Desktop/upwork/3) current projects/Learning Lab/prep_codebase.app/Contents/Resources/InfoPlist.loctable


===== File: server.js =====
/**
 * server.js
 * -----------------------------------------------------------------------------
 * Entry point for the Learning Lab Module API.
 *
 * - Loads environment variables.
 * - Connects to MongoDB.
 * - Initializes the Express application.
 * - Sets up routes and asynchronous queue worker.
 * - Starts the server.
 * -----------------------------------------------------------------------------
 */

require('dotenv').config();
const express = require('express');
const mongoose = require('mongoose');
const { initQueueWorker } = require('./services/docProcessingQueue');
const documentRoutes = require('./routes/documentRoutes');

async function initLearningLabModule() {
  // Connect to MongoDB using the URI from environment variables.
  await mongoose.connect(process.env.MONGODB_URI);

  // Initialize Express and configure middleware.
  const app = express();
  app.use(express.json());

  // Home route to confirm API is running.
  app.get('/', (req, res) => {
    res.send('Welcome to the Learning Lab Module API');
  });

  // Attach document routes under the '/documents' endpoint.
  app.use('/documents', documentRoutes);

  // Initialize the asynchronous document processing queue worker.
  initQueueWorker();

  // Start the server on the defined PORT or default to 3000.
  const PORT = process.env.PORT || 3000;
  app.listen(PORT, () => {
    console.log(`Learning Lab Module running on port ${PORT}`);
  });
}

// Immediately start the module.
initLearningLabModule();

module.exports = { initLearningLabModule };


===== File: models/documentModel.js =====
/**
 * models/documentModel.js
 * -----------------------------------------------------------------------------
 * Mongoose schema and model for Document metadata.
 * -----------------------------------------------------------------------------
 */

const mongoose = require('mongoose');

const DocumentSchema = new mongoose.Schema({
  name: { type: String, required: true },         // User-supplied or default document name.
  filename: { type: String, required: true },     // Original file name.
  fileType: { type: String, required: true },     // MIME type of the file.
  s3Key: { type: String, required: true },        // S3 key where the file is stored.
  textS3Key: { type: String },                    // S3 key for the extracted text file.
  uploadDate: { type: Date, default: Date.now },  // Timestamp of upload.
  tags: [String],                                 // Array of tags for categorization.
  status: { type: String, default: 'uploaded' },  // Processing status of the document.
  summary: { type: String },                      // Summary of the document after processing.
});

module.exports = mongoose.model('Document', DocumentSchema);


===== File: sample_documents/docs/sample.txt =====
Hello, TXT!


===== File: controllers/documentController.js =====
/**
 * controllers/documentController.js
 * -----------------------------------------------------------------------------
 * Controller functions handling document-related operations:
 *   - Uploading documents with file, name, and tags.
 *   - Adding/updating document tags.
 *   - Retrieving processing status.
 *   - Searching documents by name and tags.
 *   - Deleting documents.
 * -----------------------------------------------------------------------------
 */

const DocumentModel = require('../models/documentModel');
const { uploadFileToS3 } = require('../services/s3Service');
const { docProcessQueue } = require('../services/docProcessingQueue');
const { v4: uuidv4 } = require('uuid');
const path = require('path');

// Upload Document: Handles file upload, validation, S3 storage, and DB record creation.
async function uploadDocument(req, res) {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file provided.' });
    }
    
    // Validate file extension against disallowed executable types.
    const disallowedExtensions = ['.exe', '.bat', '.sh', '.msi', '.cmd'];
    const ext = path.extname(req.file.originalname).toLowerCase();
    if (disallowedExtensions.includes(ext)) {
      return res.status(400).json({ error: 'Executable files are not allowed.' });
    }
    
    const file = req.file;
    const fileId = uuidv4();
    const fileKey = `docs/${fileId}_${file.originalname}`;

    // Upload file buffer to S3.
    await uploadFileToS3(fileKey, file.buffer);

    // Construct S3 URI using bucket name.
    const fileUrl = `${process.env.CLOUND_FRONT_URL}/${fileKey}`;

    // Construct S3 URI using bucket name.
    const s3Uri = `s3://${process.env.S3_BUCKET}/${fileKey}`;

    // Use provided name or default to original file name.
    const name = req.body.name || file.originalname;

    // Parse tags from a comma-separated string or array.
    let tags = [];
    if (req.body.tags) {
      if (typeof req.body.tags === 'string') {
        tags = req.body.tags.split(',').map(tag => tag.trim());
      } else if (Array.isArray(req.body.tags)) {
        tags = req.body.tags;
      }
    }

    // Create a new document record in MongoDB.
    const newDoc = await DocumentModel.create({
      name: name,
      filename: file.originalname,
      fileType: file.mimetype,
      s3Key: fileKey,
      tags: tags,
    });

    // Enqueue job for asynchronous processing.
    docProcessQueue.add({ docId: newDoc._id });

    const responseMessage = {
      message: 'File uploaded successfully',
      documentId: newDoc._id,
      s3Uri: s3Uri,
    };
    console.log("Upload response:", responseMessage);
    return res.json(responseMessage);
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Upload failed.' });
  }
}

// Add or Update Tags: Updates the tags for an existing document.
async function addOrUpdateTags(req, res) {
  try {
    const { tags } = req.body;
    const docId = req.params.id;
    const doc = await DocumentModel.findById(docId);
    if (!doc) {
      return res.status(404).json({ error: 'Document not found.' });
    }
    // Only accept array of tags; otherwise default to empty array.
    doc.tags = Array.isArray(tags) ? tags : [];
    await doc.save();
    return res.json({ message: 'Tags updated.', document: doc });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Tag update failed.' });
  }
}

// Get Document Status: Retrieves the document record and processing status.
async function getDocumentStatus(req, res) {
  try {
    const doc = await DocumentModel.findById(req.params.id).lean();
    if (!doc) {
      return res.status(404).json({ error: 'Document not found.' });
    }
    return res.json({ document: doc });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Status check failed.' });
  }
}

// Search Documents: Finds documents by name (case-insensitive) and matching tags.
async function searchDocuments(req, res) {
  try {
    const { name, tags } = req.query;
    let query = {};

    if (name) {
      query.name = { $regex: name, $options: 'i' };
    }
    if (tags) {
      const tagList = typeof tags === 'string'
        ? tags.split(',').map(t => t.trim())
        : tags;
      query.tags = { $all: tagList };
    }
    const docs = await DocumentModel.find(query).lean();
    return res.json({ documents: docs });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Search failed.' });
  }
}

// Delete Document: Removes a document record from MongoDB and optionally its S3 file.
async function deleteDocument(req, res) {
  try {
    const docId = req.params.id;
    const doc = await DocumentModel.findByIdAndDelete(docId);
    if (!doc) {
      return res.status(404).json({ error: 'Document not found.' });
    }
    // Note: Consider adding S3 deletion logic here if needed.
    return res.json({ message: 'Document deleted successfully.' });
  } catch (err) {
    console.error(err);
    return res.status(500).json({ error: 'Deletion failed.' });
  }
}

module.exports = {
  uploadDocument,
  addOrUpdateTags,
  getDocumentStatus,
  searchDocuments,
  deleteDocument,
};


===== File: routes/documentRoutes.js =====
/**
 * routes/documentRoutes.js
 * -----------------------------------------------------------------------------
 * Express Router for handling document-related endpoints:
 *   - POST /upload           -> Upload a document.
 *   - POST /:id/tags         -> Add or update document tags.
 *   - GET /:id/status        -> Retrieve document processing status.
 *   - GET /                 -> Search documents by name and tags.
 *   - DELETE /:id            -> Delete a document.
 * -----------------------------------------------------------------------------
 */

const express = require('express');
const multer = require('multer');
const {
  uploadDocument,
  addOrUpdateTags,
  getDocumentStatus,
  searchDocuments,
  deleteDocument,
} = require('../controllers/documentController');

const router = express.Router();

// Configure Multer for in-memory file storage with 1GB file size limit.
const storage = multer.memoryStorage();
const upload = multer({
  storage,
  limits: { fileSize: 1024 * 1024 * 1024 }, // 1GB limit.
});

// Route definitions.
router.post('/upload', upload.single('file'), uploadDocument);
router.post('/:id/tags', addOrUpdateTags);
router.get('/:id/status', getDocumentStatus);
router.get('/', searchDocuments);
router.delete('/:id', deleteDocument);

module.exports = router;


===== File: services/docProcessingQueue.js =====
/**
 * services/docProcessingQueue.js
 * -----------------------------------------------------------------------------
 * Sets up a Bull queue for asynchronous document processing.
 *
 * Processes include:
 *   - Text extraction via AWS Textract (for images) or Transcribe (for audio/video).
 *   - Handling various file types (PDF, CSV, Excel, Word, plain text).
 *   - Uploading extracted text to S3.
 *   - Generating summaries and integrating with an LLM.
 * -----------------------------------------------------------------------------
 */
const Bull = require('bull');
const DocumentModel = require('../models/documentModel');
const { downloadFileFromS3, uploadFileToS3, deleteFileFromS3 } = require('./s3Service');
const { TextractClient, DetectDocumentTextCommand } = require("@aws-sdk/client-textract");
const { TranscribeClient, StartTranscriptionJobCommand, GetTranscriptionJobCommand } = require("@aws-sdk/client-transcribe");
const { v4: uuidv4 } = require('uuid');
const fetch = require('node-fetch');

const textractClient = new TextractClient({ region: process.env.AWS_REGION });
const transcribeClient = new TranscribeClient({ region: process.env.AWS_REGION });

const { RekognitionClient, DetectModerationLabelsCommand, StartContentModerationCommand, GetContentModerationCommand } = require('@aws-sdk/client-rekognition');
const rekognitionClient = new RekognitionClient({ region: process.env.AWS_REGION });



const docProcessQueue = new Bull('docProcessQueue', {
  redis: { host: '127.0.0.1', port: 6379 },
});


/**
 * extractTextWithAWS
 * -----------------------------------------------------------------------------
 * Uses AWS Textract for images and AWS Transcribe for audio/video files.
 *
 * @param {string} fileType - MIME type of the file.
 * @param {string} s3Bucket - S3 bucket name.
 * @param {string} s3Key - S3 key for the file.
 * @returns {string} Extracted text.
 */
async function extractTextWithAWS(fileType, s3Bucket, s3Key) {
  // For image files: use Textract.
  if (fileType.startsWith('image/')) {
    const command = new DetectDocumentTextCommand({
      Document: { S3Object: { Bucket: s3Bucket, Name: s3Key } },
    });
    const response = await textractClient.send(command);
    let extractedText = '';
    if (response.Blocks) {
      response.Blocks.forEach(block => {
        if (block.BlockType === 'LINE' && block.Text) {
          extractedText += block.Text + '\n';
        }
      });
    }
    return extractedText;
  }
  // For audio/video files: use Transcribe.
  else if (fileType.startsWith('audio/') || fileType.startsWith('video/')) {
    const jobName = `transcribe-${uuidv4()}`;
    const mediaUri = `s3://${s3Bucket}/${s3Key}`;
    const lowerKey = s3Key.toLowerCase();
    let mediaFormat = 'mp3';
    if (lowerKey.endsWith('.wav')) mediaFormat = 'wav';
    else if (lowerKey.endsWith('.mp4')) mediaFormat = 'mp4';
    else if (lowerKey.endsWith('.mov')) mediaFormat = 'mov';
    const params = {
      TranscriptionJobName: jobName,
      LanguageCode: "en-US",
      MediaFormat: mediaFormat,
      Media: { MediaFileUri: mediaUri },
      OutputBucketName: s3Bucket,
    };
    await transcribeClient.send(new StartTranscriptionJobCommand(params));
    
    // Poll until the transcription job is complete.
    let jobCompleted = false;
    let transcript = "";
    while (!jobCompleted) {
      await new Promise(resolve => setTimeout(resolve, 5000));
      const jobData = await transcribeClient.send(new GetTranscriptionJobCommand({ TranscriptionJobName: jobName }));
      const status = jobData.TranscriptionJob.TranscriptionJobStatus;
      if (status === "COMPLETED") {
        jobCompleted = true;
        const transcriptFileUri = jobData.TranscriptionJob.Transcript.TranscriptFileUri;
        const parts = transcriptFileUri.split(`/${s3Bucket}/`);
        if (parts.length < 2) {
          throw new Error("Unable to extract transcript file key from URI");
        }
        const transcriptKey = parts[1];
        const transcriptBuffer = await downloadFileFromS3(transcriptKey);
        const transcriptJson = JSON.parse(transcriptBuffer.toString('utf8'));
        transcript = transcriptJson.results.transcripts[0].transcript;
      } else if (status === "FAILED") {
        throw new Error("Transcription job failed");
      }
    }
    return transcript;
  } else {
    return "";
  }
}

/**
 * TextExtraction
 * -----------------------------------------------------------------------------
 * Determines the correct text extraction method based on file type.
 *
 * @param {Buffer} fileBuffer - The file content as a Buffer.
 * @param {string} fileType - MIME type of the file.
 * @param {string} s3Bucket - S3 bucket name.
 * @param {string} s3Key - S3 key for the file.
 * @returns {string} The extracted text.
 */
async function TextExtraction(fileBuffer, fileType, s3Bucket, s3Key) {
  const lowerKey = s3Key.toLowerCase();
  console.log("TextExtraction: fileType =", fileType, "lowerKey =", lowerKey);

  // For images: explicitly call Textract.
  if (fileType.startsWith('image/')) {
    console.log("File type indicates image. Using Textract.");
    return await extractTextWithAWS(fileType, s3Bucket, s3Key);
  }
  
  // If fileType is ambiguous.
  if (fileType === 'application/octet-stream') {
    if (lowerKey.endsWith('.mp3') || lowerKey.endsWith('.wav')) {
      console.log("Ambiguous type: Treating as audio.");
      return await extractTextWithAWS('audio/', s3Bucket, s3Key);
    }
    if (lowerKey.endsWith('.mp4') || lowerKey.endsWith('.mov')) {
      console.log("Ambiguous type: Treating as video.");
      return await extractTextWithAWS('video/', s3Bucket, s3Key);
    }
  }
  
  // If fileType explicitly indicates audio or video.
  if (fileType.startsWith('audio/') || fileType.startsWith('video/')) {
    console.log("File type indicates audio/video.");
    return await extractTextWithAWS(fileType, s3Bucket, s3Key);
  }
  // For PDFs.
  else if (fileType === 'application/pdf') {
    console.log("File type PDF detected.");
    const pdfParse = require('pdf-parse');
    const data = await pdfParse(fileBuffer);
    return data.text;
  }
  // For CSV files.
  else if (fileType === 'text/csv') {
    console.log("File type CSV detected.");
    return fileBuffer.toString('utf8');
  }
  // For Excel files.
  else if (
    fileType === 'application/vnd.ms-excel' ||
    fileType === 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
  ) {
    console.log("File type Excel detected.");
    const xlsx = require('xlsx');
    const workbook = xlsx.read(fileBuffer, { type: 'buffer' });
    let text = '';
    workbook.SheetNames.forEach(sheetName => {
      const sheet = workbook.Sheets[sheetName];
      text += xlsx.utils.sheet_to_csv(sheet);
    });
    return text;
  }
  // For Word documents.
  else if (
    fileType === 'application/msword' ||
    fileType === 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
  ) {
    console.log("File type Word detected.");
    const mammoth = require('mammoth');
    const result = await mammoth.extractRawText({ buffer: fileBuffer });
    return result.value;
  }
  // Default: treat as plain text.
  else {
    console.log("Default branch: Treating as plain text.");
    return fileBuffer.toString('utf8');
  }
}

/**
 * checkContentModeration
 * -----------------------------------------------------------------------------
 * Performs content moderation on a file based on its MIME type.
 * - For image files: Uses AWS Rekognition's DetectModerationLabelsCommand to
 *   check the file buffer for any NSFW content.
 * - For video files: Initiates a content moderation job with AWS Rekognition,
 *   polls for the results, and checks for any NSFW labels.
 *
 * @param {string} fileType - The MIME type of the file.
 * @param {Buffer} fileBuffer - The file's content as a Buffer (used for images).
 * @param {string} s3Bucket - The name of the S3 bucket where the file is stored.
 * @param {string} s3Key - The S3 object key identifying the file.
 * @returns {Promise<boolean>} A promise that resolves to true if any NSFW content is detected, false otherwise.
 * @throws {Error} Throws an error if the content moderation process fails.
 */
async function checkContentModeration(fileType, fileBuffer, s3Bucket, s3Key) {
  if (fileType.startsWith('image/')) {
    const command = new DetectModerationLabelsCommand({
      Image: { Bytes: fileBuffer },
      MinConfidence: 80,
    });
    const response = await rekognitionClient.send(command);
    return response.ModerationLabels && response.ModerationLabels.length > 0;
  } else if (fileType.startsWith('video/')) {
    const startCommand = new StartContentModerationCommand({
      Video: { S3Object: { Bucket: s3Bucket, Name: s3Key } },
      MinConfidence: 80,
    });
    const startResponse = await rekognitionClient.send(startCommand);
    const jobId = startResponse.JobId;
    let moderationLabels = [];
    for (let i = 0; i < 12; i++) { // Poll up to ~120 sec
      await new Promise(resolve => setTimeout(resolve, 10000));
      const getCommand = new GetContentModerationCommand({ JobId: jobId });
      const getResponse = await rekognitionClient.send(getCommand);
      if (getResponse.JobStatus === 'SUCCEEDED') {
        moderationLabels = getResponse.ModerationLabels;
        break;
      }
    }
    return moderationLabels && moderationLabels.length > 0;
  }
  return false;
}



/**
 * initQueueWorker
 * -----------------------------------------------------------------------------
 * Initializes the Bull queue worker to process document jobs.
 */
function initQueueWorker() {
  console.log("Initializing Queue Worker...");

  docProcessQueue.process(async (job) => {
    try {
      console.log("Processing job:", job.id);
      const { docId } = job.data;
      const docRecord = await DocumentModel.findById(docId);
      if (!docRecord) throw new Error('Document not found in DB');
      console.log("Document record found:", docRecord);

      // 1. Download file from S3
      console.log("Downloading file from S3 with key:", docRecord.s3Key);
      const fileBuffer = await downloadFileFromS3(docRecord.s3Key);
      console.log("File downloaded, size:", fileBuffer.length);

      // Content Moderation for images/videos
      if (docRecord.fileType.startsWith('image/') || docRecord.fileType.startsWith('video/')) {
        console.log("Performing content moderation check...");
        const flagged = await checkContentModeration(docRecord.fileType, fileBuffer, process.env.S3_BUCKET, docRecord.s3Key);
        if (flagged) {
          console.log("Content moderation flagged the file. Deleting from S3...");
          await deleteFileFromS3(docRecord.s3Key);
          docRecord.status = 'deleted due to content moderation';
          await docRecord.save();
          return;
        }
      }

      // Only extract and upload transcript if file is audio or video.
      if (docRecord.fileType.startsWith('audio/') || docRecord.fileType.startsWith('video/')) {
        console.log("Extracting transcript for audio/video file...");
        const extractedText = await TextExtraction(
          fileBuffer,
          docRecord.fileType,
          process.env.S3_BUCKET,
          docRecord.s3Key
        );
        console.log("Transcript extracted (first 100 chars):", extractedText.substring(0, 100));

        const originalKey = docRecord.s3Key;
        const filenamePart = originalKey.split('/')[1];
        const baseName = filenamePart.replace(/\.[^/.]+$/, "");
        const transcriptKey = `text/${baseName}_transcript.txt`;
        await uploadFileToS3(transcriptKey, Buffer.from(extractedText, 'utf8'));
        console.log("Extracted transcript stored at S3 key:", transcriptKey);
        docRecord.textS3Key = transcriptKey;
      } else {
        console.log("Skipping transcript extraction for non-audio/video file.");
      }

      // Update MongoDB record: mark as processed.
      docRecord.status = 'processed';
      await docRecord.save();
      console.log("Document record updated successfully for job:", job.id);
    } catch (error) {
      console.error("Error processing job", job.id, error);
      throw error;
    }
  });

  console.log("Queue Worker is set up and listening for jobs.");
}


module.exports = {
  docProcessQueue,
  initQueueWorker,
};


===== File: services/s3Service.js =====
/**
 * services/s3Service.js
 * -----------------------------------------------------------------------------
 * Provides AWS S3 integration for file uploads, downloads, and deletions.
 * -----------------------------------------------------------------------------
 */

const { S3Client, PutObjectCommand, GetObjectCommand, DeleteObjectCommand } = require('@aws-sdk/client-s3');
const { PassThrough } = require('stream');

const REGION = process.env.AWS_REGION || 'us-east-1';
const BUCKET_NAME = process.env.S3_BUCKET;
const s3Client = new S3Client({ region: REGION });

/**
 * streamToBuffer
 * -----------------------------------------------------------------------------
 * Converts a readable stream into a Buffer.
 *
 * @param {Stream} stream - The readable stream.
 * @returns {Promise<Buffer>} A promise that resolves to the complete Buffer.
 */
async function streamToBuffer(stream) {
  return new Promise((resolve, reject) => {
    const chunks = [];
    stream.on('data', (chunk) => chunks.push(chunk));
    stream.on('error', reject);
    stream.on('end', () => resolve(Buffer.concat(chunks)));
  });
}

/**
 * uploadFileToS3
 * -----------------------------------------------------------------------------
 * Uploads a file buffer to S3 at the specified key.
 *
 * @param {string} key - The S3 object key.
 * @param {Buffer} buffer - The file content.
 * @returns {Promise<void>} A promise that resolves when the file is uploaded.
 */
async function uploadFileToS3(key, buffer) {
  const command = new PutObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
    Body: buffer,
  });
  await s3Client.send(command);
}

/**
 * downloadFileFromS3
 * -----------------------------------------------------------------------------
 * Downloads a file from S3 and returns its content as a Buffer.
 *
 * @param {string} key - The S3 object key.
 * @returns {Promise<Buffer>} A promise that resolves to the file content as a Buffer.
 */
async function downloadFileFromS3(key) {
  const command = new GetObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
  });
  const data = await s3Client.send(command);
  return await streamToBuffer(data.Body);
}

/**
 * deleteFileFromS3
 * -----------------------------------------------------------------------------
 * Deletes a file from the specified S3 bucket using the provided key.
 *
 * @param {string} key - The unique S3 object key identifying the file to be deleted.
 * @returns {Promise<void>} A promise that resolves once the file has been deleted.
 */
async function deleteFileFromS3(key) {
  const command = new DeleteObjectCommand({
    Bucket: BUCKET_NAME,
    Key: key,
  });
  await s3Client.send(command);
}

module.exports = {
  uploadFileToS3,
  downloadFileFromS3,
  deleteFileFromS3,
};


